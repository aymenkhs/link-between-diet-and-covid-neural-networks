# -*- coding: utf-8 -*-
"""aarn_pretreatment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18VbEG7i65iFUS2dSK2DspqhJbKGvBcEW
"""
import os

import pandas as pd
import numpy as np

data_folder = "data"

# data covid
raw_covid_data = pd.read_csv(os.path.join(data_folder, "data.csv"))

# we don't need the columns about countries and continent except "countryterritoryCode"
raw_covid_data = raw_covid_data.drop(["countriesAndTerritories", "geoId", "continentExp"] ,axis="columns")

# list of countries
countries = raw_covid_data.countryterritoryCode.unique()
covid_data = pd.DataFrame(columns = ["country", "death_toll", "total_cases"])

countries = [country for country in countries if not pd.isnull(country)]

for country in countries:
  country_data = raw_covid_data[raw_covid_data["countryterritoryCode"] == country]

  country_pop = country_data["popData2019"].iloc[0]

  # calculating the death toll and total cases depending on the size of the population
  death_toll = country_data["deaths"].sum() / country_pop * 100
  total_cases = country_data["cases"].sum() / country_pop * 10

  # decide if we're gonna ignore the country

  #adding a new line to covid cases
  covid_data = covid_data.append({"country":country, "death_toll":death_toll, "total_cases":total_cases}, ignore_index=True)


index_taiwan = covid_data["country"].tolist().index("CNG1925")
covid_data.at[index_taiwan, "country"] = "TWN"

# diet data treatement
files_name = os.listdir(os.path.join(data_folder, "Country-level_estimates"))
files_name.sort()

first_line = True

# read all the datasets in "coutry-level estimates"
diet_data = pd.DataFrame()
for file in files_name:
  data_aliment = pd.read_csv(os.path.join(data_folder, "Country-level_estimates", file))

  type_food = data_aliment["varnum"].iloc[0]

  # we don't need the columns "superregion2", "vXX_type_desc" and "vXX_type"
  formated_type_food = '{0}'.format(str(type_food).zfill(2))
  data_aliment = data_aliment.drop(["superregion2", "v{}_type_desc".format(formated_type_food), "v{}_type".format(formated_type_food)] ,axis="columns")

  # we're gonna take into consideraion only the 2018 data
  mask2018 = data_aliment["year"] == 2018
  data_aliment = data_aliment[mask2018]

  # we're gonna take into consideration only the "999" value of age, edu, urban and female (wich means all our data without taking into consideration these groups)
  # because we don't have separate data for the age, sex, eduction...etc in covid dataset so make no sens to take them into consideration
  mask999 = data_aliment["age"] == 999
  data_aliment = data_aliment[mask999]

  mask999 = data_aliment["urban"] == 999
  data_aliment = data_aliment[mask999]

  mask999 = data_aliment["female"] == 999
  data_aliment = data_aliment[mask999]

  mask999 = data_aliment["edu"] == 999
  data_aliment = data_aliment[mask999]

  # we merge our datasets
  data_aliment = data_aliment[["iso3", "median"]]
  data_aliment.columns = ['country', "medianV{}".format(type_food)]

  if first_line:
    first_line = False
    diet_data = data_aliment
  else:
    diet_data = pd.merge(diet_data, data_aliment, on='country')

# merging the data

final_data = pd.merge(diet_data, covid_data, on='country')

final_data = final_data.drop("country", axis="columns")

final_data.to_csv("final_data.csv", index=False)
