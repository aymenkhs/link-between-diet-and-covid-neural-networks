# -*- coding: utf-8 -*-
"""aarn_pretreatment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18VbEG7i65iFUS2dSK2DspqhJbKGvBcEW
"""

# telecharger les données

# telecharge les données du GDD
!wget https://www.globaldietarydatabase.org/sites/default/files/gdd-data-downloads/20210607/GDD-FinalEstimates_06072021.zip

# on decompresse le fichier et supprimme les dossiers "Region-level estimates" et "Global-level estimates" car ils ne seront pas utiliser
!unzip GDD-FinalEstimates_06072021.zip
!rm -r "Region-level estimates"
!rm -r "Global-level estimates"

# telecharge les données sur COVID19
!wget https://opendata.ecdc.europa.eu/covid19/casedistribution/csv/data.csv

# data covid
import pandas as pd
import numpy as np

raw_covid_data = pd.read_csv("data.csv")

# make a masque to ignore the vaccines (maybe nov 2020?)

# we don't need the columns about countries and continent except "countryterritoryCode"
raw_covid_data = raw_covid_data.drop(["countriesAndTerritories", "geoId", "continentExp"] ,axis="columns")

# after removing the problematic dates (after the vaccine) we remove the dates columns

# list of countries 
countries = raw_covid_data.countryterritoryCode.unique() 
covid_data = pd.DataFrame(columns = ["country", "death_toll", "total_cases"])

countries = [country for country in countries if not pd.isnull(country)]

for country in countries:
  country_data = raw_covid_data[raw_covid_data["countryterritoryCode"] == country]

  country_pop = country_data["popData2019"].iloc[0]
  
  # calculating the death toll and total cases depending on the size of the population
  death_toll = country_data["deaths"].sum() / country_pop * 100
  total_cases = country_data["cases"].sum() / country_pop * 10

  # decide if we're gonna ignore the country

  #adding a new line to covid cases
  covid_data = covid_data.append({"country":country, "death_toll":death_toll, "total_cases":total_cases}, ignore_index=True)


index_taiwan = covid_data["country"].tolist().index("CNG1925")
covid_data.at[index_taiwan, "country"] = "TWN"

covid_data

# diet data

import pandas as pd
import os


files_name = os.listdir("Country-level estimates")
files_name.sort()

first_line = False

# read all the datasets in "coutry-level estimates"
diet_data = pd.DataFrame()
for file in files_name:
  data_aliment = pd.read_csv(os.path.join("Country-level estimates", file))

  type_food = data_aliment["varnum"].iloc[0]
  
  # we don't need the columns "superregion2", "vXX_type_desc" and "vXX_type"
  formated_type_food = '{0}'.format(str(type_food).zfill(2))
  data_aliment = data_aliment.drop(["superregion2", "v{}_type_desc".format(formated_type_food), "v{}_type".format(formated_type_food)] ,axis="columns")
  
  # we're gonna take into consideraion only the 2018 data
  mask2018 = data_aliment["year"] == 2018
  data_aliment = data_aliment[mask2018]

  # we're gonna take into consideration only the "999" value of age, edu, urban and female (wich means all our data without taking into consideration these groups)
  # because we don't have separate data for the age, sex, eduction...etc in covid dataset so make no sens to take them into consideration  
  mask999 = data_aliment["age"] == 999
  data_aliment = data_aliment[mask999]
  
  mask999 = data_aliment["urban"] == 999
  data_aliment = data_aliment[mask999]

  mask999 = data_aliment["female"] == 999
  data_aliment = data_aliment[mask999]

  mask999 = data_aliment["edu"] == 999
  data_aliment = data_aliment[mask999]

  # we merge our datasets
  data_aliment = data_aliment[["iso3", "median"]]
  data_aliment.columns = ['country', "medianV{}".format(type_food)]
  
  if not first_line:
    diet_data = data_aliment
  else:
    diet_data = pd.merge(diet_data, data_aliment, on='country')

print(diet_data)

# merging the data

print(set(diet_data["country"]).difference(set(covid_data["country"])))
print(set(covid_data["country"]).difference(set(diet_data["country"])))

final_data = pd.merge(diet_data, covid_data, on='country')

final_data = final_data.drop("country", axis="columns")
final_data = final_data.drop(final_data.columns[0], axis="columns")

final_data.to_csv("final_data.csv", index=False)